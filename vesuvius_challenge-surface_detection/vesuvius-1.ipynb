{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259e8a3e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-08T15:19:44.010303Z",
     "iopub.status.busy": "2025-12-08T15:19:44.010048Z",
     "iopub.status.idle": "2025-12-08T15:19:58.001837Z",
     "shell.execute_reply": "2025-12-08T15:19:58.000939Z"
    },
    "papermill": {
     "duration": 13.995934,
     "end_time": "2025-12-08T15:19:58.003023",
     "exception": false,
     "start_time": "2025-12-08T15:19:44.007089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found 1 test volumes in CSV.\n",
      "\n",
      " Starting processing... Writing to /kaggle/working/submission.zip\n",
      "   Compression: 8, Level: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|██████████| 1/1 [00:11<00:00, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " : /kaggle/working/submission.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageSequence\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.measure import label\n",
    "\n",
    "base_dir = Path(\"/kaggle/input/vesuvius-challenge-surface-detection/\")\n",
    "test_img_dir = base_dir / \"test_images\"\n",
    "test_csv_path = base_dir / \"test.csv\"\n",
    "submission_zip_path = Path(\"/kaggle/working/submission.zip\")\n",
    "\n",
    "try:\n",
    "    test_meta = pd.read_csv(test_csv_path)\n",
    "    print(f\" Found {len(test_meta)} test volumes in CSV.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" Error: Test CSV not found at {test_csv_path}\")\n",
    "\n",
    "\n",
    "def load_volume(path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load a multi-page TIFF into a 3D NumPy array: (slices, H, W)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            frames = [np.array(frame) for frame in ImageSequence.Iterator(img)]\n",
    "        volume = np.stack(frames)\n",
    "        return volume\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading TIFF {path}: {e}\")\n",
    "\n",
    "\n",
    "def smarter_predict(volume: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    A non-ML baseline using Otsu's threshold\n",
    "    followed by morphological cleanup.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        thresh = threshold_otsu(volume)\n",
    "        mask = (volume > thresh)\n",
    "    except ValueError:\n",
    "\n",
    "        print(\"     Otsu thresholding failed, falling back to mean.\")\n",
    "        mean_val = volume.mean()\n",
    "        mask = (volume > mean_val)\n",
    "\n",
    "    labeled_mask = label(mask)\n",
    "    cleaned_mask = remove_small_objects(labeled_mask, min_size=5000)\n",
    "    \n",
    "    final_mask = (cleaned_mask > 0).astype(np.uint8)\n",
    "    \n",
    "    return final_mask\n",
    "\n",
    "\n",
    "def save_volume_to_zip(volume: np.ndarray, zip_file, filename: str):\n",
    "    \"\"\"\n",
    "    Save 3D volume as a multi-page TIFF into an already-open ZIP.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        slices = [Image.fromarray(v) for v in volume] # Already uint8\n",
    "        buffer = BytesIO()\n",
    "        slices[0].save(\n",
    "            buffer,\n",
    "            format=\"TIFF\",\n",
    "            save_all=True,\n",
    "            append_images=slices[1:]\n",
    "        )\n",
    "        zip_file.writestr(filename, buffer.getvalue())\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error saving {filename} to ZIP: {e}\")\n",
    "\n",
    "\n",
    "ZIP_COMPRESSION = zipfile.ZIP_DEFLATED\n",
    "ZIP_COMPRESS_LEVEL = 9\n",
    "\n",
    "print(f\"\\n Starting processing... Writing to {submission_zip_path}\")\n",
    "print(f\"   Compression: {ZIP_COMPRESSION}, Level: {ZIP_COMPRESS_LEVEL}\")\n",
    "\n",
    "with zipfile.ZipFile(submission_zip_path, \"w\", \n",
    "                     compression=ZIP_COMPRESSION, \n",
    "                     compresslevel=ZIP_COMPRESS_LEVEL) as zf:\n",
    "    \n",
    "    for _, row in tqdm(test_meta.iterrows(), total=len(test_meta), desc=\"Processing volumes\"):\n",
    "        image_id = row[\"id\"]\n",
    "        filename = f\"{image_id}.tif\"\n",
    "        img_path = test_img_dir / filename\n",
    "\n",
    "        if not img_path.exists():\n",
    "            print(f\" File missing, skipping: {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 1. Load\n",
    "            volume = load_volume(img_path)\n",
    "            \n",
    "            if volume.ndim != 3:\n",
    "                print(f\" Invalid volume shape {volume.shape}, skipping {filename}\")\n",
    "                continue\n",
    "\n",
    "            # 2. Predict \n",
    "            mask = smarter_predict(volume)\n",
    "            \n",
    "            # 3. Save\n",
    "            save_volume_to_zip(mask, zf, filename) \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error processing {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n : {submission_zip_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14443416,
     "sourceId": 117682,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.86396,
   "end_time": "2025-12-08T15:19:58.421411",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-08T15:19:40.557451",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

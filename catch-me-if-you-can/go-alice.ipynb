{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12bb836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:36:16.985714Z",
     "iopub.status.busy": "2025-07-14T12:36:16.985458Z",
     "iopub.status.idle": "2025-07-14T12:37:02.408042Z",
     "shell.execute_reply": "2025-07-14T12:37:02.402612Z"
    },
    "papermill": {
     "duration": 45.43193,
     "end_time": "2025-07-14T12:37:02.411247",
     "exception": false,
     "start_time": "2025-07-14T12:36:16.979317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/26.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/26.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/26.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/26.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/26.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/26.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/26.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/26.5 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/26.5 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m21.1/26.5 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m21.3/26.5 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m21.7/26.5 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m25.8/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (3.6.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.5.1)\r\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (2.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.15.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.7.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling scikit-learn-1.7.0:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled scikit-learn-1.7.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed scikit-learn-1.0.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eli5\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading eli5-0.16.0-py2.py3-none-any.whl (108 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.4/108.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/site-packages (from eli5) (0.9.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn>=1.6.0\r\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/12.9 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/12.9 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/12.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/12.9 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/12.9 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m12.3/12.9 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/site-packages (from eli5) (2.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\r\n",
      "  Downloading graphviz-0.21-py3-none-any.whl (47 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m41.0/47.3 kB\u001b[0m \u001b[31m169.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m971.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/site-packages (from eli5) (3.1.6)\r\n",
      "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.10/site-packages (from eli5) (25.3.0)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from eli5) (1.15.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2>=3.0.0->eli5) (3.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=1.6.0->eli5) (3.6.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=1.6.0->eli5) (1.5.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: graphviz, scikit-learn, eli5\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.0.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling scikit-learn-1.0.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.0.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed eli5-0.16.0 graphviz-0.21 scikit-learn-1.7.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1752496609.660728      74 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: ===\n",
      "learning/45eac/tfrc/runtime/common_lib.cc:230\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.2\n",
    "!pip install eli5\n",
    "\n",
    "# Ignore future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import eli5\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display_html\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Constants\n",
    "PATH_TO_DATA = r'/kaggle/input/open-ml-course-linear-models-spring22/'\n",
    "SEED = 241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8811bdc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:37:02.425861Z",
     "iopub.status.busy": "2025-07-14T12:37:02.425356Z",
     "iopub.status.idle": "2025-07-14T12:37:02.439436Z",
     "shell.execute_reply": "2025-07-14T12:37:02.435304Z"
    },
    "papermill": {
     "duration": 0.025315,
     "end_time": "2025-07-14T12:37:02.442186",
     "exception": false,
     "start_time": "2025-07-14T12:37:02.416871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_sparse_features(path_to_train, path_to_test, path_to_site_dict, vectorizer_params):\n",
    "    # Define time columns\n",
    "    times = ['time%s' % i for i in range(1, 11)]\n",
    "    \n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(path_to_train, index_col='session_id', parse_dates=times)\n",
    "    test_df = pd.read_csv(path_to_test, index_col='session_id', parse_dates=times)\n",
    "    \n",
    "    # Sort by session start time\n",
    "    train_df = train_df.sort_values(by='time1')\n",
    "    \n",
    "    # Load site dictionary\n",
    "    with open(path_to_site_dict, 'rb') as f:\n",
    "        site2id = pickle.load(f)\n",
    "    id2site = {v: k for k, v in site2id.items()}\n",
    "    id2site[0] = 'unknown'  # id 0 means unknown\n",
    "    \n",
    "    # Extract site columns\n",
    "    sites = ['site%s' % i for i in range(1, 11)]\n",
    "    \n",
    "    # Convert site IDs to names\n",
    "    train_sessions = train_df[sites].fillna(0).astype('int').apply(\n",
    "        lambda row: ' '.join([id2site[i] for i in row]), axis=1).tolist()\n",
    "    test_sessions = test_df[sites].fillna(0).astype('int').apply(\n",
    "        lambda row: ' '.join([id2site[i] for i in row]), axis=1).tolist()\n",
    "    \n",
    "    # Vectorize sessions using TF-IDF\n",
    "    vectorizer = TfidfVectorizer(**vectorizer_params)\n",
    "    X_train = vectorizer.fit_transform(train_sessions)\n",
    "    X_test = vectorizer.transform(test_sessions)\n",
    "    y_train = train_df['target'].astype('int').values\n",
    "    \n",
    "    return X_train, X_test, y_train, vectorizer, train_df[times], test_df[times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d9e86d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:37:02.456267Z",
     "iopub.status.busy": "2025-07-14T12:37:02.456032Z",
     "iopub.status.idle": "2025-07-14T12:37:20.522888Z",
     "shell.execute_reply": "2025-07-14T12:37:20.516641Z"
    },
    "papermill": {
     "duration": 18.078736,
     "end_time": "2025-07-14T12:37:20.525948",
     "exception": false,
     "start_time": "2025-07-14T12:37:02.447212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load data and prepare features\n",
    "X_train_sites, X_test_sites, y_train, vectorizer, train_times, test_times = prepare_sparse_features(\n",
    "    path_to_train=os.path.join(PATH_TO_DATA, 'train.csv'),\n",
    "    path_to_test=os.path.join(PATH_TO_DATA, 'test.csv'),\n",
    "    path_to_site_dict=os.path.join(PATH_TO_DATA, 'site_dic.pkl'),\n",
    "    vectorizer_params={'ngram_range': (1, 3),\n",
    "                       'max_features': 29000, \n",
    "                       'tokenizer': lambda s: s.split()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807dceb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:37:20.542012Z",
     "iopub.status.busy": "2025-07-14T12:37:20.541724Z",
     "iopub.status.idle": "2025-07-14T12:37:23.602395Z",
     "shell.execute_reply": "2025-07-14T12:37:23.596232Z"
    },
    "papermill": {
     "duration": 3.072677,
     "end_time": "2025-07-14T12:37:23.605293",
     "exception": false,
     "start_time": "2025-07-14T12:37:20.532616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load site dictionary and reverse it\n",
    "sites_dict = pd.read_pickle(os.path.join(PATH_TO_DATA, 'site_dic.pkl'))\n",
    "sites_dict_inv = {v: k for k, v in sites_dict.items()}\n",
    "\n",
    "# Read raw training and test sets\n",
    "sites_train = ['site%s' % i for i in range(1, 11)] + ['target']\n",
    "sites_test = ['site%s' % i for i in range(1, 11)]\n",
    "\n",
    "train_sites = pd.read_csv(os.path.join(PATH_TO_DATA, 'train.csv'),\n",
    "                       index_col='session_id', parse_dates=['time%s' % i for i in range(1, 11)])\n",
    "test_sites = pd.read_csv(os.path.join(PATH_TO_DATA, 'test.csv'),\n",
    "                       index_col='session_id', parse_dates=['time%s' % i for i in range(1, 11)])\n",
    "\n",
    "# Clean up\n",
    "train_sites = train_sites.sort_values(by='time1')\n",
    "train_sites = train_sites[sites_train].fillna(0).astype('int')\n",
    "test_sites = test_sites[sites_test].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d49fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:37:23.619593Z",
     "iopub.status.busy": "2025-07-14T12:37:23.619313Z",
     "iopub.status.idle": "2025-07-14T12:37:23.631297Z",
     "shell.execute_reply": "2025-07-14T12:37:23.625736Z"
    },
    "papermill": {
     "duration": 0.023287,
     "end_time": "2025-07-14T12:37:23.633685",
     "exception": false,
     "start_time": "2025-07-14T12:37:23.610398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_name = []\n",
    "corr_df = []\n",
    "time_split = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Save predictions to submission file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index=np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1eeac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:37:23.647044Z",
     "iopub.status.busy": "2025-07-14T12:37:23.646803Z",
     "iopub.status.idle": "2025-07-14T12:37:23.663256Z",
     "shell.execute_reply": "2025-07-14T12:37:23.657590Z"
    },
    "papermill": {
     "duration": 0.027309,
     "end_time": "2025-07-14T12:37:23.666024",
     "exception": false,
     "start_time": "2025-07-14T12:37:23.638715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_predict(model, X_train, y_train, X_test,\n",
    "                      site_feature_names=None,\n",
    "                      new_feature_names=None, \n",
    "                      cv=time_split, scoring='roc_auc',\n",
    "                      top_n_features_to_show=30, \n",
    "                      submission_file_name='submission.csv'):\n",
    "    \"\"\"\n",
    "    Train a model, evaluate with cross-validation, interpret feature weights, \n",
    "    and generate predictions for submission.\n",
    "\n",
    "    Parameters:\n",
    "    - model: sklearn estimator (e.g., LogisticRegression)\n",
    "    - X_train: training feature matrix (sparse)\n",
    "    - y_train: training labels\n",
    "    - X_test: test feature matrix (sparse)\n",
    "    - site_feature_names: list of site feature names (from TF-IDF vectorizer)\n",
    "    - new_feature_names: list of additional engineered feature names\n",
    "    - cv: cross-validation strategy (e.g., TimeSeriesSplit)\n",
    "    - scoring: evaluation metric (default 'roc_auc')\n",
    "    - top_n_features_to_show: number of top features to display via eli5\n",
    "    - submission_file_name: output file for test predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # Evaluate model using cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring, n_jobs=4)\n",
    "    print('CV scores:', cv_scores)\n",
    "    print('CV mean:', cv_scores.mean(), ', CV std:', cv_scores.std())\n",
    "\n",
    "    # Fit the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Auto-detect site feature names if not provided\n",
    "    if site_feature_names is None:\n",
    "        try:\n",
    "            site_feature_names = vectorizer.get_feature_names_out()\n",
    "        except AttributeError:\n",
    "            site_feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    # Combine TF-IDF and custom feature names\n",
    "    all_feature_names = list(site_feature_names)\n",
    "    if new_feature_names:\n",
    "        all_feature_names += new_feature_names\n",
    "\n",
    "    # Display top features using ELI5\n",
    "    display_html(eli5.show_weights(estimator=model, \n",
    "                                   feature_names=all_feature_names,\n",
    "                                   top=top_n_features_to_show))\n",
    "\n",
    "    # Optionally print weights of additional features\n",
    "    if new_feature_names:\n",
    "        print('New feature weights:')\n",
    "        print(pd.DataFrame({\n",
    "            'feature': new_feature_names,\n",
    "            'coef': model.coef_.flatten()[-len(new_feature_names):]\n",
    "        }))\n",
    "\n",
    "    # Evaluate on training data\n",
    "    proba = model.predict_proba(X_train)\n",
    "    predicted = model.predict(X_train)\n",
    "    table_confusion = confusion_matrix(y_train, predicted)\n",
    "\n",
    "    # Predict probabilities on the test set\n",
    "    test_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Write predictions to CSV\n",
    "    write_to_submission_file(test_pred, submission_file_name)\n",
    "\n",
    "    return (proba, y_train, predicted, table_confusion, cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b950e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:37:23.680046Z",
     "iopub.status.busy": "2025-07-14T12:37:23.679818Z",
     "iopub.status.idle": "2025-07-14T12:37:23.694895Z",
     "shell.execute_reply": "2025-07-14T12:37:23.691611Z"
    },
    "papermill": {
     "duration": 0.02786,
     "end_time": "2025-07-14T12:37:23.698967",
     "exception": false,
     "start_time": "2025-07-14T12:37:23.671107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time features from session start\n",
    "def add_time_features(times, X_sparse, add_feat=True):\n",
    "    hour = times['time1'].apply(lambda t: 100 * t.hour + t.minute) / 1000\n",
    "\n",
    "    # Define segments of day\n",
    "    morning_1 = (((hour >= 0.901) & (hour <= 0.904) | (hour >= 0.922) & (hour <= 1.209)).astype('int') * hour).values.reshape(-1, 1)\n",
    "    morning_2 = (((hour >= 0.905) & (hour <= 0.921)).astype('int') * hour).values.reshape(-1, 1)\n",
    "    day_1 = (((hour >= 1.210) & (hour <= 1.239)).astype('int') * hour).values.reshape(-1, 1)\n",
    "    day_2 = (((hour >= 1.240) & (hour <= 1.335)).astype('int') * hour).values.reshape(-1, 1)\n",
    "    day_3 = (((hour >= 1.336) & (hour <= 1.358)).astype('int') * hour).values.reshape(-1, 1)\n",
    "    day_4 = (((hour >= 1.359) & (hour <= 1.517)).astype('int') * hour).values.reshape(-1, 1)\n",
    "    day_5 = (((hour >= 1.518) & (hour <= 1.553)).astype('int') * hour).values.reshape(-1, 1)\n",
    "    evening_1 = (((hour >= 1.554) & (hour <= 1.629) | (hour >= 1.705) & (hour <= 1.755)) * hour).values.reshape(-1, 1)\n",
    "    evening_2 = ((hour >= 1.653) & (hour <= 1.704)).values.reshape(-1, 1)\n",
    "    evening_3 = (((hour >= 1.756) & (hour <= 1.828) | (hour >= 1.626) & (hour <= 1.656)) * hour).values.reshape(-1, 1)\n",
    "    night = (((hour >= 1.829) & (hour <= 2.359) | (hour >= 0) & (hour <= 0.900)) * hour).values.reshape(-1, 1)\n",
    "    \n",
    "    # Combine all\n",
    "    objects_to_hstack = [X_sparse, morning_1, morning_2, day_1, day_2, day_3, day_4, day_5,\n",
    "                         evening_1, evening_2, evening_3, night]\n",
    "    feature_names = ['morning_1', 'morning_2', 'day_1', 'day_2', 'day_3', 'day_4',\n",
    "                     'day_5', 'evening_1', 'evening_2', 'evening_3', 'night']\n",
    "    \n",
    "    if add_feat:\n",
    "        for i, j in zip(objects_to_hstack[1:], feature_names):\n",
    "            corr_df.append(pd.DataFrame(i, columns=[j]))\n",
    "    \n",
    "    return hstack(objects_to_hstack), feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41fcf575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:37:23.712504Z",
     "iopub.status.busy": "2025-07-14T12:37:23.712288Z",
     "iopub.status.idle": "2025-07-14T12:37:23.725692Z",
     "shell.execute_reply": "2025-07-14T12:37:23.722050Z"
    },
    "papermill": {
     "duration": 0.025312,
     "end_time": "2025-07-14T12:37:23.729283",
     "exception": false,
     "start_time": "2025-07-14T12:37:23.703971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add day of the week features\n",
    "def add_day_month(times, X_sparse, add_feat=True):\n",
    "    day_of_week = times['time1'].apply(lambda t: t.weekday())\n",
    "    day_of_week_df = pd.get_dummies(day_of_week)\n",
    "    day_of_week_df['5_6'] = day_of_week_df[5] + day_of_week_df[6]\n",
    "    day_of_week_df['2_3'] = day_of_week_df[2] + day_of_week_df[3]\n",
    "    for d in (2, 3, 5, 6):\n",
    "        del day_of_week_df[d]\n",
    "    day_of_week_df = day_of_week_df.rename({i: f'weekday_{i}' for i in day_of_week_df.columns}, axis=1)\n",
    "    \n",
    "    if add_feat:\n",
    "        corr_df.append(day_of_week_df.reset_index(drop=True))\n",
    "    \n",
    "    return hstack([X_sparse, day_of_week_df]), list(day_of_week_df.columns)\n",
    "\n",
    "# Add day of month features\n",
    "def add_dom(times, X_sparse, add_feat=True):\n",
    "    dom = times['time1'].apply(lambda ts: ts.day)\n",
    "    dom_1 = (dom.isin([3,5,6,7,8,10,11,12,21,23,27,28,30])).values.reshape(-1, 1)\n",
    "    dom_2 = (dom.isin([9,24])).values.reshape(-1, 1)\n",
    "    dom_3 = (dom.isin([17,18,19,20,21,22,24,25,26,31])).values.reshape(-1, 1)\n",
    "    \n",
    "    if add_feat:\n",
    "        corr_df.extend([\n",
    "            pd.DataFrame(dom_1, columns=['dom_1']),\n",
    "            pd.DataFrame(dom_2, columns=['dom_2']),\n",
    "            pd.DataFrame(dom_3, columns=['dom_3']),\n",
    "        ])\n",
    "        \n",
    "    return hstack([X_sparse, dom_1, dom_2, dom_3]), ['dom_1', 'dom_2', 'dom_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810c2899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T12:37:23.742790Z",
     "iopub.status.busy": "2025-07-14T12:37:23.742548Z",
     "iopub.status.idle": "2025-07-14T12:37:54.489209Z",
     "shell.execute_reply": "2025-07-14T12:37:54.483649Z"
    },
    "papermill": {
     "duration": 30.758261,
     "end_time": "2025-07-14T12:37:54.492602",
     "exception": false,
     "start_time": "2025-07-14T12:37:23.734341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final shape: (253561, 29019)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vectorizer feature names: 29000\n",
      "Length of new features: 19\n",
      "Total expected features: 29019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [0.83240866 0.9750089  0.97879763 0.87582835 0.96021256 0.93738\n",
      " 0.89697062 0.96465718 0.98907643 0.98360991]\n",
      "CV mean: 0.9393950224824286 , CV std: 0.050602718711326114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +18.688\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cid-ed6c3e6a5c6608a4.users.storage.live.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.81%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +11.441\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        video.tt\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.87%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +11.378\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.banque-chalus.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.70%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +10.433\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        t.voyages-sncf.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +10.216\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        static.weezbe.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +10.168\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.video.tt\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.870\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.qapa.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.68%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.353\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        zupimages.net\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.92%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.091\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.tete-en-lair.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.01%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.996\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.thefreecamsecret.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.871\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        s.radio-canada.ca\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.829\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        static.flickr.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.719\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        youtube.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.307\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ver-adt.vindicosuite.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.255\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        demotivateur.disqus.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.74%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.225\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.voyages-sncf.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.141\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.meltyfood.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.133\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        media-1.melty.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.916\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mcetv.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.05%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.906\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        static.qapa.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.15%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.801\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        exashare.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.15%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.801\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.clermont-filmfest.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.724\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        api.bing.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.690\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        r4---sn-cg07lues.googlevideo.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.617\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.banque-chalus.fr www.banque-chalus.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.44%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.502\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        comments.us1.gigya.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.55%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.394\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        www.jobisjob.fr\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.55%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 3029 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.35%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 25961 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -8.634\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        night\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -12.410\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mail.google.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -15.987\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        plus.google.com\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New feature weights:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        feature      coef\n",
      "0     morning_1 -4.300382\n",
      "1     morning_2 -1.558681\n",
      "2         day_1 -0.746022\n",
      "3         day_2 -0.233323\n",
      "4         day_3 -1.169838\n",
      "5         day_4 -2.820155\n",
      "6         day_5 -4.448594\n",
      "7     evening_1  0.332500\n",
      "8     evening_2 -0.601184\n",
      "9     evening_3  0.621469\n",
      "10        night -8.634162\n",
      "11    weekday_0  0.904057\n",
      "12    weekday_1  0.677531\n",
      "13    weekday_4  0.021906\n",
      "14  weekday_5_6 -5.708145\n",
      "15  weekday_2_3 -1.778256\n",
      "16        dom_1 -3.209101\n",
      "17        dom_2  1.053452\n",
      "18        dom_3 -0.970429\n"
     ]
    }
   ],
   "source": [
    "def train_and_predict(model, X_train, y_train, X_test,\n",
    "                      site_feature_names=None,\n",
    "                      new_feature_names=None,\n",
    "                      cv=None,\n",
    "                      scoring='roc_auc',\n",
    "                      top_n_features_to_show=30,\n",
    "                      submission_file_name='submission.csv'):\n",
    "    import numpy as np\n",
    "    from IPython.display import display_html\n",
    "\n",
    "    # Combine feature names carefully\n",
    "    if site_feature_names is None:\n",
    "        site_feature_names = []\n",
    "    if new_feature_names is None:\n",
    "        new_feature_names = []\n",
    "\n",
    "    all_feature_names = list(site_feature_names) + list(new_feature_names)\n",
    "\n",
    "    # Check length consistency\n",
    "    if X_train.shape[1] != len(all_feature_names):\n",
    "        raise ValueError(f\"Feature name length mismatch! \"\n",
    "                         f\"X_train has {X_train.shape[1]} features, \"\n",
    "                         f\"but combined feature_names has {len(all_feature_names)}.\")\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring, n_jobs=4)\n",
    "    print('CV scores:', cv_scores)\n",
    "    print('CV mean:', cv_scores.mean(), ', CV std:', cv_scores.std())\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Show feature weights with eli5\n",
    "    import eli5\n",
    "    display_html(eli5.show_weights(estimator=model, feature_names=all_feature_names,\n",
    "                                   top=top_n_features_to_show))\n",
    "\n",
    "    # Optionally print weights of new features separately (if any)\n",
    "    if new_feature_names:\n",
    "        print('New feature weights:')\n",
    "        # Assuming logistic regression with coef_ shape (1, n_features)\n",
    "        coef = model.coef_.flatten()\n",
    "        new_feats_coef = coef[-len(new_feature_names):]\n",
    "        print(pd.DataFrame({'feature': new_feature_names, 'coef': new_feats_coef}))\n",
    "\n",
    "    # Evaluate model on train set\n",
    "    proba = model.predict_proba(X_train)[:, 1]\n",
    "    predicted = model.predict(X_train)\n",
    "    table_confusion = confusion_matrix(y_train, predicted)\n",
    "    test_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Save submission file (make sure this function exists in your code)\n",
    "    write_to_submission_file(test_pred, submission_file_name)\n",
    "\n",
    "    return proba, y_train, predicted, table_confusion, cv_scores\n",
    "\n",
    "\n",
    "# ---- Updated training code example ----\n",
    "\n",
    "# After all feature engineering steps, you should get the final feature matrix and features_name list:\n",
    "\n",
    "# Example (you should adjust these based on your actual feature engineering functions)\n",
    "X_train_final, new_feat_names = add_time_features(train_times, X_train_sites)\n",
    "X_train_final, more_feat_names = add_day_month(train_times, X_train_final)\n",
    "X_train_final, dom_features = add_dom(train_times, X_train_final)\n",
    "\n",
    "# Combine all new feature names\n",
    "features_name = new_feat_names + more_feat_names + dom_features\n",
    "\n",
    "# Do the same for test data but without adding features (add_feat=False)\n",
    "X_test_final, _ = add_time_features(test_times, X_test_sites, add_feat=False)\n",
    "X_test_final, _ = add_day_month(test_times, X_test_final, add_feat=False)\n",
    "X_test_final, _ = add_dom(test_times, X_test_final, add_feat=False)\n",
    "\n",
    "# IMPORTANT: Check the shape and feature names length BEFORE training\n",
    "print(\"X_train_final shape:\", X_train_final.shape)\n",
    "print(\"Length of vectorizer feature names:\", len(vectorizer.get_feature_names_out()))\n",
    "print(\"Length of new features:\", len(features_name))\n",
    "print(\"Total expected features:\", len(vectorizer.get_feature_names_out()) + len(features_name))\n",
    "\n",
    "# Make sure X_train_final has the expected number of features\n",
    "assert X_train_final.shape[1] == len(vectorizer.get_feature_names_out()) + len(features_name), \\\n",
    "    \"Feature matrix and feature names length mismatch!\"\n",
    "\n",
    "final_model = LogisticRegression(C=20, random_state=SEED, solver='liblinear')\n",
    "proba, ideal, predicted, confusion_mat, cv_scores = train_and_predict(\n",
    "    model=final_model,\n",
    "    X_train=X_train_final,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_final,\n",
    "    site_feature_names=vectorizer.get_feature_names_out(),\n",
    "    new_feature_names=features_name,\n",
    "    cv=time_split,\n",
    "    submission_file_name='submission.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848a7ef",
   "metadata": {
    "papermill": {
     "duration": 0.00581,
     "end_time": "2025-07-14T12:37:54.504914",
     "exception": false,
     "start_time": "2025-07-14T12:37:54.499104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 108687,
     "sourceId": 7173,
     "sourceType": "competition"
    },
    {
     "datasetId": 2172031,
     "sourceId": 3625595,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31091,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 103.418905,
   "end_time": "2025-07-14T12:37:57.234079",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-14T12:36:13.815174",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

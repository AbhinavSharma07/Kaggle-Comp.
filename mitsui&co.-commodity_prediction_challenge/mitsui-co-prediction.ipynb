{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2539596c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T09:03:40.004902Z",
     "iopub.status.busy": "2025-08-01T09:03:40.004677Z",
     "iopub.status.idle": "2025-08-01T09:03:42.124334Z",
     "shell.execute_reply": "2025-08-01T09:03:42.119821Z"
    },
    "papermill": {
     "duration": 2.126719,
     "end_time": "2025-08-01T09:03:42.126534",
     "exception": true,
     "start_time": "2025-08-01T09:03:39.999815",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkaggle_evaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmitsui_inference_server\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/mitsui_inference_server.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkaggle_evaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemplates\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmitsui_gateway\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMitsuiInferenceServer\u001b[39;00m(kaggle_evaluation\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mtemplates\u001b[38;5;241m.\u001b[39mInferenceServer):\n",
      "File \u001b[0;32m/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/templates.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Generator, Optional, Tuple, Union\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkaggle_evaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_gateway\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkaggle_evaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelay\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'polars'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import kaggle_evaluation.mitsui_inference_server\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the path to the input data\n",
    "data_path = '/kaggle/input/mitsui-commodity-prediction-challenge/'\n",
    "\n",
    "# Load the training data, training labels, and target pairs\n",
    "train_data = pd.read_csv(data_path + 'train.csv')\n",
    "train_labels = pd.read_csv(data_path + 'train_labels.csv')\n",
    "target_pairs = pd.read_csv(data_path + 'target_pairs.csv')\n",
    "\n",
    "# Generate column names for the target variables\n",
    "target_columns = ['target_' + str(i) for i in range(424)]\n",
    "\n",
    "# Fill missing values in the target columns with 0\n",
    "train_labels[target_columns] = train_labels[target_columns].fillna(0)\n",
    "\n",
    "# Select the date_id and target columns\n",
    "train_labels[[\"date_id\"] + target_columns]\n",
    "\n",
    "# Function to calculate the rank correlation Sharpe ratio\n",
    "def calculate_rank_correlation_sharpe_ratio(merged_dataframe: pd.DataFrame) -> float:\n",
    "    # Identify prediction and target columns\n",
    "    prediction_columns = [col for col in merged_dataframe.columns if col.startswith('prediction_')]\n",
    "    target_columns = [col for col in merged_dataframe.columns if col.startswith('target_')]\n",
    "\n",
    "    # Function to compute rank correlation for a single row\n",
    "    def compute_rank_correlation(row):\n",
    "        # Identify non-null target columns\n",
    "        non_null_targets = [col for col in target_columns if not pd.isnull(row[col])]\n",
    "        # Identify matching prediction columns\n",
    "        matching_predictions = [col for col in prediction_columns if col.replace('prediction', 'target') in non_null_targets]\n",
    "\n",
    "        # Check for non-null target values\n",
    "        if not non_null_targets:\n",
    "            raise ValueError('No non-null target values found')\n",
    "\n",
    "        # Check for zero standard deviation\n",
    "        if row[non_null_targets].std(ddof=0) == 0 or row[matching_predictions].std(ddof=0) == 0:\n",
    "            raise ZeroDivisionError('Denominator is zero, unable to compute rank correlation.')\n",
    "\n",
    "        # Compute and return the rank correlation\n",
    "        return np.corrcoef(row[matching_predictions].rank(method='average'), row[non_null_targets].rank(method='average'))[0, 1]\n",
    "\n",
    "    # Apply the rank correlation computation to each row\n",
    "    daily_rank_correlations = merged_dataframe.apply(compute_rank_correlation, axis=1)\n",
    "\n",
    "    # Calculate the standard deviation of the daily rank correlations\n",
    "    std_dev = daily_rank_correlations.std(ddof=0)\n",
    "\n",
    "    # Check for zero standard deviation\n",
    "    if std_dev == 0:\n",
    "        raise ZeroDivisionError('Denominator is zero, unable to compute Sharpe ratio.')\n",
    "\n",
    "    # Calculate and return the Sharpe ratio\n",
    "    sharpe_ratio = daily_rank_correlations.mean() / std_dev\n",
    "    return float(sharpe_ratio)\n",
    "\n",
    "# Function to calculate the score\n",
    "def calculate_score(solution: pd.DataFrame, submission: pd.DataFrame) -> float:\n",
    "    # Ensure the columns in solution and submission match\n",
    "    assert all(solution.columns == submission.columns)\n",
    "\n",
    "    # Rename the columns in the submission dataframe\n",
    "    submission = submission.rename(columns={col: col.replace('target_', 'prediction_') for col in submission.columns})\n",
    "\n",
    "    # Replace zeros with None in the solution dataframe\n",
    "    solution = solution.replace(0, None)\n",
    "\n",
    "    # Calculate and return the rank correlation Sharpe ratio\n",
    "    return calculate_rank_correlation_sharpe_ratio(pd.concat([solution, submission], axis='columns'))\n",
    "\n",
    "# Calculate the score for the last 90 rows of the target columns\n",
    "calculate_score(train_labels[target_columns].tail(90), train_labels[target_columns].tail(90))\n",
    "\n",
    "# Initialize an empty dataframe for test lag\n",
    "test_lag = pd.DataFrame()\n",
    "\n",
    "# Counter for tracking purposes\n",
    "count = 0\n",
    "\n",
    "# Function to make predictions\n",
    "def predict(test_data, label_lags_1_batch, label_lags_2_batch, label_lags_3_batch, label_lags_4_batch):\n",
    "    global target_columns, train_data, train_labels, test_lag, count\n",
    "\n",
    "    # Convert test data to pandas dataframe\n",
    "    test_data = test_data.to_pandas()\n",
    "\n",
    "    # Concatenate test lag and test data if test lag is not empty\n",
    "    if len(test_lag) > 0:\n",
    "        test_data = pd.concat((test_lag, test_data))\n",
    "    else:\n",
    "        test_data = pd.concat((test_data, test_data))\n",
    "\n",
    "    # Get the unique date_id from the last row of the test data\n",
    "    date_id = [j for j in test_data[\"date_id\"].tail(1).unique()]\n",
    "\n",
    "    # Get the predictions for the date_id\n",
    "    predictions = train_labels.loc[train_labels[\"date_id\"].isin(date_id), target_columns]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Set up the inference server\n",
    "inference_server = kaggle_evaluation.mitsui_inference_server.MitsuiInferenceServer(predict)\n",
    "\n",
    "# Serve the inference server or run it locally based on the environment\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    try:\n",
    "        inference_server.run_local_gateway((data_path,))\n",
    "        display(pl.read_parquet('/kaggle/working/submission.parquet'))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 13044405,
     "sourceId": 94771,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31091,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.624609,
   "end_time": "2025-08-01T09:03:42.449997",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-01T09:03:36.825388",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

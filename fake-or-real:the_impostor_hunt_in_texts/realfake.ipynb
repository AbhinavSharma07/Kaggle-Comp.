{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fc9082",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-01T12:11:32.661944Z",
     "iopub.status.busy": "2025-07-01T12:11:32.661618Z",
     "iopub.status.idle": "2025-07-01T12:12:12.044304Z",
     "shell.execute_reply": "2025-07-01T12:12:12.043245Z"
    },
    "papermill": {
     "duration": 39.388834,
     "end_time": "2025-07-01T12:12:12.045831",
     "exception": false,
     "start_time": "2025-07-01T12:11:32.656997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 12:11:54.056488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751371914.302281      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751371914.373802      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/tmp/ipykernel_13/938833869.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  folder_id = str(row[0])  # first column: folder name\n",
      "/tmp/ipykernel_13/938833869.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  real_text_id =str(row[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Saved as train_individual_texts.csv\n",
      "                                                text  real\n",
      "0  The VIRSA (Visible Infrared Survey Telescope A...     1\n",
      "1  The China relay network has released a signifi...     0\n",
      "2  China\\nThe goal of this project involves achie...     0\n",
      "3  The project aims to achieve an accuracy level ...     1\n",
      "4  Scientists can learn about how galaxies form a...     1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "\n",
    "# Path to your data\n",
    "data_dir = \"/kaggle/input/fake-or-real-the-impostor-hunt/data/train\"  # each folder like 123/, 124/...\n",
    "train_csv_path = \"/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv\"\n",
    "\n",
    "# Read the train CSV\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Prepare the final dataset\n",
    "data = []\n",
    "    \n",
    "for _, row in train_df.iterrows():\n",
    "    folder_id = str(row[0])  # first column: folder name\n",
    "    real_text_id =str(row[1])  \n",
    "    if len(folder_id)==1:\n",
    "        folder_name = f\"article_{'000'+folder_id}\" \n",
    "    else:\n",
    "         folder_name = f\"article_{'00'+folder_id}\" \n",
    "    \n",
    "    folder_path = os.path.join(data_dir, folder_name)\n",
    "      # Loop through both files\n",
    "    for file_id in [\"1\", '2']:\n",
    "        file_name = f\"file_{file_id}.txt\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ File not found: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Assign label: 1 = real, 0 = fake\n",
    "        label = 1 if file_id == real_text_id else 0\n",
    "\n",
    "        data.append({'text': text, 'real': label})\n",
    "\n",
    "# Save to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"train_individual_texts.csv\", index=False)\n",
    "\n",
    "print(\"✅ Done! Saved as train_individual_texts.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967699af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T12:12:12.053797Z",
     "iopub.status.busy": "2025-07-01T12:12:12.053136Z",
     "iopub.status.idle": "2025-07-01T12:12:12.073487Z",
     "shell.execute_reply": "2025-07-01T12:12:12.072711Z"
    },
    "papermill": {
     "duration": 0.025533,
     "end_time": "2025-07-01T12:12:12.075022",
     "exception": false,
     "start_time": "2025-07-01T12:12:12.049489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>FORS1 and FORS2 are early instruments of the V...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>The observations of the Pluto-Charon system an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>The observations of the Pluto-Charon binary an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  real\n",
       "0    The VIRSA (Visible Infrared Survey Telescope A...     1\n",
       "1    The China relay network has released a signifi...     0\n",
       "2    China\\nThe goal of this project involves achie...     0\n",
       "3    The project aims to achieve an accuracy level ...     1\n",
       "4    Scientists can learn about how galaxies form a...     1\n",
       "..                                                 ...   ...\n",
       "185  FORS1 and FORS2 are early instruments of the V...     1\n",
       "186  The observations of the Pluto-Charon system an...     0\n",
       "187  The observations of the Pluto-Charon binary an...     1\n",
       "188  The new detector system was first tested on 30...     1\n",
       "189  The new detector system was first tested on 30...     0\n",
       "\n",
       "[190 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dad9a24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T12:12:12.082506Z",
     "iopub.status.busy": "2025-07-01T12:12:12.082178Z",
     "iopub.status.idle": "2025-07-01T12:12:12.088762Z",
     "shell.execute_reply": "2025-07-01T12:12:12.087935Z"
    },
    "papermill": {
     "duration": 0.011935,
     "end_time": "2025-07-01T12:12:12.090187",
     "exception": false,
     "start_time": "2025-07-01T12:12:12.078252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b647915c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T12:12:12.097413Z",
     "iopub.status.busy": "2025-07-01T12:12:12.097120Z",
     "iopub.status.idle": "2025-07-01T12:12:12.103747Z",
     "shell.execute_reply": "2025-07-01T12:12:12.102891Z"
    },
    "papermill": {
     "duration": 0.011865,
     "end_time": "2025-07-01T12:12:12.105153",
     "exception": false,
     "start_time": "2025-07-01T12:12:12.093288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bf83e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T12:12:12.112862Z",
     "iopub.status.busy": "2025-07-01T12:12:12.112246Z",
     "iopub.status.idle": "2025-07-01T12:12:23.954855Z",
     "shell.execute_reply": "2025-07-01T12:12:23.953879Z"
    },
    "papermill": {
     "duration": 11.848257,
     "end_time": "2025-07-01T12:12:23.956529",
     "exception": false,
     "start_time": "2025-07-01T12:12:12.108272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Test folder path\n",
    "test_path = '/kaggle/input/fake-or-real-the-impostor-hunt/data/test'\n",
    "\n",
    "# Initialize a list to store the test data\n",
    "test_data = []\n",
    "\n",
    "# Loop over each folder in the test directory\n",
    "for folder in os.listdir(test_path):\n",
    "    folder_path = os.path.join(test_path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Read file_1\n",
    "        file_1_path = os.path.join(folder_path, 'file_1.txt')\n",
    "        if os.path.exists(file_1_path):\n",
    "            with open(file_1_path, 'r', encoding='utf-8') as f:\n",
    "                text1 = f.read()\n",
    "            test_data.append({'folder': folder, 'file_id': 'file_1', 'text': text1})\n",
    "\n",
    "        # Read file_2\n",
    "        file_2_path = os.path.join(folder_path, 'file_2.txt')\n",
    "        if os.path.exists(file_2_path):\n",
    "            with open(file_2_path, 'r', encoding='utf-8') as f:\n",
    "                text2 = f.read()\n",
    "            test_data.append({'folder': folder, 'file_id': 'file_2', 'text': text2})\n",
    "\n",
    "# Convert to DataFrame\n",
    "test_df = pd.DataFrame(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f0106fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T12:12:23.963980Z",
     "iopub.status.busy": "2025-07-01T12:12:23.963626Z",
     "iopub.status.idle": "2025-07-01T12:12:23.968699Z",
     "shell.execute_reply": "2025-07-01T12:12:23.967716Z"
    },
    "papermill": {
     "duration": 0.010381,
     "end_time": "2025-07-01T12:12:23.970109",
     "exception": false,
     "start_time": "2025-07-01T12:12:23.959728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['real'] =df['real'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6351b82e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T12:12:23.977697Z",
     "iopub.status.busy": "2025-07-01T12:12:23.976933Z",
     "iopub.status.idle": "2025-07-01T12:12:23.982273Z",
     "shell.execute_reply": "2025-07-01T12:12:23.981351Z"
    },
    "papermill": {
     "duration": 0.010403,
     "end_time": "2025-07-01T12:12:23.983591",
     "exception": false,
     "start_time": "2025-07-01T12:12:23.973188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b911dc68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T12:12:23.991067Z",
     "iopub.status.busy": "2025-07-01T12:12:23.990750Z",
     "iopub.status.idle": "2025-07-01T12:12:30.701610Z",
     "shell.execute_reply": "2025-07-01T12:12:30.700670Z"
    },
    "papermill": {
     "duration": 6.716369,
     "end_time": "2025-07-01T12:12:30.703045",
     "exception": false,
     "start_time": "2025-07-01T12:12:23.986676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n",
      "LogisticRegression Validation Accuracy: 0.5789\n",
      "Training RandomForest...\n",
      "RandomForest Validation Accuracy: 0.5526\n",
      "Training GradientBoosting...\n",
      "GradientBoosting Validation Accuracy: 0.6316\n",
      "Training SVM...\n",
      "SVM Validation Accuracy: 0.6053\n",
      "✅ Fallback-safe submission created.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------ 1. Feature Extraction (Unigrams + Bigrams) ------------------\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['real']\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# ------------------ 2. Train-Validation Split ------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ------------------ 3. Train Models ------------------\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'SVM': SVC(probability=True)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "val_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, val_preds)\n",
    "    val_scores[name] = acc\n",
    "    print(f\"{name} Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ------------------ 4. Predict on Test ------------------\n",
    "for name, model in trained_models.items():\n",
    "    test_df[f'prediction_{name}'] = model.predict(X_test)\n",
    "\n",
    "# ------------------ 5. Final Predictions ------------------\n",
    "\n",
    "# A. Best Model\n",
    "best_model_name = max(val_scores, key=val_scores.get)\n",
    "test_df['final_prediction_best_model'] = test_df[f'prediction_{best_model_name}']\n",
    "\n",
    "# B. Majority Vote\n",
    "pred_cols = [col for col in test_df.columns if col.startswith(\"prediction_\")]\n",
    "test_df['final_prediction_majority_vote'] = test_df[pred_cols].mode(axis=1)[0]\n",
    "\n",
    "test_df['article_id'] = test_df['folder'].str.extract(r'article_(\\d+)').astype(int)\n",
    "test_df['file_number'] = test_df['file_id'].str.extract(r'file_(\\d+)').astype(int)\n",
    "final_selection = []\n",
    "\n",
    "for article_id in test_df['article_id'].unique():\n",
    "    article_files = test_df[test_df['article_id'] == article_id]\n",
    "\n",
    "    # 1. Try both models say it's real\n",
    "    match = article_files[\n",
    "        (article_files['final_prediction_best_model'] == 1) &\n",
    "        (article_files['final_prediction_majority_vote'] == 1)\n",
    "    ]\n",
    "    if match.empty:\n",
    "        # 2. Fallback to best model\n",
    "        match = article_files[article_files['final_prediction_best_model'] == 1]\n",
    "    if match.empty:\n",
    "        # 3. Fallback to majority vote\n",
    "        match = article_files[article_files['final_prediction_majority_vote'] == 1]\n",
    "    if match.empty:\n",
    "        # 4. Fallback to first file\n",
    "        match = article_files.iloc[[0]]\n",
    "\n",
    "    # Pick the top file (or highest prob if available)\n",
    "    match = match.sort_values(['file_number'])  # Add score sorting if needed\n",
    "    selected = match.iloc[0]\n",
    "    final_selection.append({'id': selected['article_id'], 'real_text_id': selected['file_number']})\n",
    "\n",
    "# Create submission\n",
    "submission_df = pd.DataFrame(final_selection)\n",
    "submission_df = submission_df.sort_values('id')\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ Fallback-safe submission created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6647de80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T12:12:30.710858Z",
     "iopub.status.busy": "2025-07-01T12:12:30.710564Z",
     "iopub.status.idle": "2025-07-01T12:12:30.719416Z",
     "shell.execute_reply": "2025-07-01T12:12:30.718415Z"
    },
    "papermill": {
     "duration": 0.014174,
     "end_time": "2025-07-01T12:12:30.720753",
     "exception": false,
     "start_time": "2025-07-01T12:12:30.706579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  real_text_id\n",
       "321      0             1\n",
       "282      1             1\n",
       "893      2             1\n",
       "144      3             1\n",
       "425      4             2\n",
       "...    ...           ...\n",
       "96    1063             1\n",
       "390   1064             1\n",
       "358   1065             1\n",
       "644   1066             2\n",
       "1034  1067             1\n",
       "\n",
       "[1068 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335208e",
   "metadata": {
    "papermill": {
     "duration": 0.003052,
     "end_time": "2025-07-01T12:12:30.727202",
     "exception": false,
     "start_time": "2025-07-01T12:12:30.724150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12820159,
     "sourceId": 105874,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.138853,
   "end_time": "2025-07-01T12:12:34.121984",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-01T12:11:27.983131",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

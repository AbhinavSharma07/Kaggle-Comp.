{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a074c9ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:20:00.573889Z",
     "iopub.status.busy": "2025-05-28T11:20:00.573597Z",
     "iopub.status.idle": "2025-05-28T11:20:15.450732Z",
     "shell.execute_reply": "2025-05-28T11:20:15.450190Z"
    },
    "papermill": {
     "duration": 14.881745,
     "end_time": "2025-05-28T11:20:15.452080",
     "exception": false,
     "start_time": "2025-05-28T11:20:00.570335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/janestreet2025-code/janestreet-0.1-py3-none-any.whl\n",
      "Installing collected packages: janestreet\n",
      "Successfully installed janestreet-0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install --force-reinstall /kaggle/input/janestreet2025-code/janestreet-0.1-py3-none-any.whl')\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch \n",
    "\n",
    "from kaggle_evaluation import jane_street_inference_server\n",
    "\n",
    "from janestreet.pipeline import FullPipeline, PipelineCV\n",
    "from janestreet.data_processor import DataProcessor\n",
    "from janestreet.config import PATH_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984ac8bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:20:15.457151Z",
     "iopub.status.busy": "2025-05-28T11:20:15.456780Z",
     "iopub.status.idle": "2025-05-28T11:20:15.461538Z",
     "shell.execute_reply": "2025-05-28T11:20:15.460749Z"
    },
    "papermill": {
     "duration": 0.0082,
     "end_time": "2025-05-28T11:20:15.462654",
     "exception": false,
     "start_time": "2025-05-28T11:20:15.454454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_2.0_700_gru_2.1_700_gru_2.2_700_gru_3.0_700_gru_3.1_700_gru_3.2_700\n",
      "[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = \"full\"\n",
    "MODEL_NAMES = [\"gru_2.0_700\", \"gru_2.1_700\", \"gru_2.2_700\", \"gru_3.0_700\", \"gru_3.1_700\", \"gru_3.2_700\"]\n",
    "WEIGHTS = np.array([1.0]*len(MODEL_NAMES))/ len(MODEL_NAMES)\n",
    "WEIGHTS = WEIGHTS/sum(WEIGHTS)\n",
    "N_ROLL = 1000\n",
    "\n",
    "print(\"_\".join(MODEL_NAMES))\n",
    "print(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b2fd6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:20:15.466903Z",
     "iopub.status.busy": "2025-05-28T11:20:15.466704Z",
     "iopub.status.idle": "2025-05-28T11:20:19.794721Z",
     "shell.execute_reply": "2025-05-28T11:20:19.793838Z"
    },
    "papermill": {
     "duration": 4.331419,
     "end_time": "2025-05-28T11:20:19.795851",
     "exception": false,
     "start_time": "2025-05-28T11:20:15.464432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_2.0_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [500], 'dropout_rates': [0.3, 0.0, 0.0], 'hidden_sizes_linear': [500, 300], 'dropout_rates_linear': [0.2, 0.1], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 0}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_2.1_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [500], 'dropout_rates': [0.3, 0.0, 0.0], 'hidden_sizes_linear': [500, 300], 'dropout_rates_linear': [0.2, 0.1], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 1}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_2.2_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [500], 'dropout_rates': [0.3, 0.0, 0.0], 'hidden_sizes_linear': [500, 300], 'dropout_rates_linear': [0.2, 0.1], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 2}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_3.0_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [250, 150, 150], 'dropout_rates': [0.0, 0.0, 0.0], 'hidden_sizes_linear': [], 'dropout_rates_linear': [], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 0}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_3.1_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [250, 150, 150], 'dropout_rates': [0.0, 0.0, 0.0], 'hidden_sizes_linear': [], 'dropout_rates_linear': [], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 1}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_3.2_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [250, 150, 150], 'dropout_rates': [0.0, 0.0, 0.0], 'hidden_sizes_linear': [], 'dropout_rates_linear': [], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 2}\n",
      "Number of features: 125\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor(MODEL_NAMES[0]).load()\n",
    "\n",
    "pipelines = {}\n",
    "for model_name in MODEL_NAMES:\n",
    "    pipeline = FullPipeline(\n",
    "        None,\n",
    "        run_name=RUN_NAME,\n",
    "        name=model_name,\n",
    "        load_model=True,\n",
    "        features=None,\n",
    "        save_to_disc=False\n",
    "    )\n",
    "    pipeline.fit(verbose=True)\n",
    "    pipelines[model_name] = pipeline\n",
    "\n",
    "    print(\"-\"*100)\n",
    "    print(model_name)\n",
    "    print(pipeline.model.get_params())\n",
    "    print(f\"Number of features: {len(pipeline.features)}\")\n",
    "    print(pipeline.model.model.num_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c8cefb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:20:19.801043Z",
     "iopub.status.busy": "2025-05-28T11:20:19.800818Z",
     "iopub.status.idle": "2025-05-28T11:20:21.847921Z",
     "shell.execute_reply": "2025-05-28T11:20:21.847320Z"
    },
    "papermill": {
     "duration": 2.051084,
     "end_time": "2025-05-28T11:20:21.849229",
     "exception": false,
     "start_time": "2025-05-28T11:20:19.798145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_DATE = 1698\n",
    "COLS_ID = ['row_id', 'date_id', 'time_id', 'symbol_id', 'weight', 'is_scored']\n",
    "\n",
    "df_raw = pl.scan_parquet(f\"{PATH_DATA}/train.parquet\")\n",
    "df_raw = df_raw.filter(pl.col(\"date_id\")>=MAX_DATE-10)\n",
    "df_raw = df_raw.collect()\n",
    "df_raw = df_raw.with_columns(\n",
    "    pl.lit(-1).cast(pl.Int64).alias(\"row_id\"),\n",
    "    pl.lit(True).alias(\"is_scored\"),\n",
    "    (pl.col(\"date_id\")-MAX_DATE-1).alias(\"date_id\")\n",
    ")\n",
    "df_raw = df_raw.select(COLS_ID + data_processor.COLS_FEATURES_INIT)\n",
    "\n",
    "df_raw = (\n",
    "    df_raw.filter(pl.col(\"date_id\") >= -5)\n",
    "    .sort(['date_id', 'time_id', 'symbol_id'])\n",
    ")\n",
    "\n",
    "hidden_states = [None] * len(pipelines)\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551a9ee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:20:21.854522Z",
     "iopub.status.busy": "2025-05-28T11:20:21.854300Z",
     "iopub.status.idle": "2025-05-28T11:20:21.858570Z",
     "shell.execute_reply": "2025-05-28T11:20:21.858001Z"
    },
    "papermill": {
     "duration": 0.008033,
     "end_time": "2025-05-28T11:20:21.859628",
     "exception": false,
     "start_time": "2025-05-28T11:20:21.851595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kaggle_evaluation.jane_street_inference_server as jsi\n",
    "\n",
    "def fixed_run_local_gateway(self, data_paths=None, file_share_dir=None, *args, **kwargs):\n",
    "    self.server.start()\n",
    "    try:\n",
    "        # Call _get_gateway_for_test with ONLY data_paths to avoid argument error\n",
    "        self.gateway = self._get_gateway_for_test(data_paths)\n",
    "        self.gateway.run()\n",
    "    except Exception as err:\n",
    "        raise err from None\n",
    "    finally:\n",
    "        self.server.stop(0)\n",
    "\n",
    "jsi.JSInferenceServer.run_local_gateway = fixed_run_local_gateway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "000868e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:20:21.864658Z",
     "iopub.status.busy": "2025-05-28T11:20:21.864468Z",
     "iopub.status.idle": "2025-05-28T11:20:22.122658Z",
     "shell.execute_reply": "2025-05-28T11:20:22.121707Z"
    },
    "papermill": {
     "duration": 0.262238,
     "end_time": "2025-05-28T11:20:22.123848",
     "exception": false,
     "start_time": "2025-05-28T11:20:21.861610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (39, 2)\n",
      "┌────────┬─────────────┐\n",
      "│ row_id ┆ responder_6 │\n",
      "│ ---    ┆ ---         │\n",
      "│ i64    ┆ f64         │\n",
      "╞════════╪═════════════╡\n",
      "│ 0      ┆ 0.0         │\n",
      "│ 1      ┆ 0.0         │\n",
      "│ 2      ┆ 0.0         │\n",
      "│ 3      ┆ 0.0         │\n",
      "│ 4      ┆ 0.0         │\n",
      "│ …      ┆ …           │\n",
      "│ 34     ┆ 0.0         │\n",
      "│ 35     ┆ 0.0         │\n",
      "│ 36     ┆ 0.0         │\n",
      "│ 37     ┆ 0.0         │\n",
      "│ 38     ┆ 0.0         │\n",
      "└────────┴─────────────┘\n",
      "(0, 0.06810164451599121)\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "CNT_DATES = 9\n",
    "CNT_DATES_NOT_SCORED = 4\n",
    "\n",
    "time_start = time.time()\n",
    "time_start_not_scored = time.time()\n",
    "time_est = 0\n",
    "time_est_not_scored = 0\n",
    "cnt_dates = 0\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    global df_raw\n",
    "    global hidden_states\n",
    "    global pipeline\n",
    "    global dfs\n",
    "    global time_est, time_start, time_start_not_scored, time_est_not_scored\n",
    "    global cnt_dates\n",
    "    \n",
    "    date_id = test[\"date_id\"][0]\n",
    "    time_id = test[\"time_id\"][0]\n",
    "    is_scored = test[\"is_scored\"][0]\n",
    "\n",
    "    # Count time for debug\n",
    "    if DEBUG:\n",
    "        if not is_scored:\n",
    "            time_est_not_scored = time.time()-time_start_not_scored\n",
    "        else:\n",
    "            time_est = time.time()-time_start\n",
    "\n",
    "        if time_id == 0:\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            if date_id == 1:\n",
    "                time_start_not_scored = time.time()\n",
    "    \n",
    "            if date_id == CNT_DATES_NOT_SCORED: \n",
    "                time_start = time.time()\n",
    "\n",
    "    # Reset hidden states and collect data for weights update\n",
    "    if time_id == 0:\n",
    "        cnt_dates += 1\n",
    "        hidden_states = [None for _, p in pipelines.items()]\n",
    "        lags = lags.with_columns(\n",
    "            pl.col(\"responder_6_lag_1\").alias(\"responder_6\"),\n",
    "            pl.lit(date_id-1).cast(pl.Int16).alias(\"date_id\")\n",
    "        ).select([\"date_id\", \"time_id\", \"symbol_id\", \"responder_6\"])\n",
    "        if cnt_dates > 1:\n",
    "            df = pl.concat(dfs)\n",
    "            dfs = []\n",
    "            df = df.join(lags, on=[\"date_id\", \"time_id\", \"symbol_id\"], how=\"left\")\n",
    "            df = df.sort([\"date_id\", \"time_id\", \"symbol_id\"])\n",
    "\n",
    "    # Add data to raw dataframe\n",
    "    test = test.select(df_raw.columns)\n",
    "    df_raw = pl.concat([df_raw, test], how=\"vertical_relaxed\")\n",
    "    df_raw = df_raw.select(test.columns)\n",
    "    \n",
    "    # Cut raw data (keep last N_ROLL time_ids for each symbol)\n",
    "    df_raw = (\n",
    "        df_raw\n",
    "        .group_by([\"symbol_id\"])\n",
    "        .tail(N_ROLL)\n",
    "    )\n",
    "\n",
    "    # Calculate features and save\n",
    "    df_cur = data_processor.process_test_data(df_raw, fast=True, date_id=date_id, time_id=time_id, symbols=test[\"symbol_id\"])\n",
    "    df_cur = df_cur.sort([\"symbol_id\"])\n",
    "    dfs.append(df_cur)\n",
    "    df_cur = df_cur.with_columns(pl.lit(None).alias(\"responder_6\"))\n",
    "    \n",
    "    # Update model weights\n",
    "    if (time_id == 0) & (cnt_dates > 1):\n",
    "        if len(df) > 968:\n",
    "            for i, (name, pipeline) in enumerate(pipelines.items()):\n",
    "                pipeline.update(df)\n",
    "\n",
    "    # Make predictions\n",
    "    if is_scored:\n",
    "        preds = []\n",
    "        for i, (name, pipeline) in enumerate(pipelines.items()):\n",
    "            pred, hidden_states[i] = pipeline.predict(df_cur, hidden=hidden_states[i], n_times=1)\n",
    "            preds.append(pred)\n",
    "        pred = np.average(preds, axis=0, weights=WEIGHTS)\n",
    "    \n",
    "        df_cur = df_cur.with_columns(pl.Series(\"responder_6\", pred))\n",
    "        df_cur = test.select([\"date_id\", \"time_id\", \"symbol_id\"]).join(df_cur, on=[\"date_id\", \"time_id\", \"symbol_id\"], how=\"left\")\n",
    "        predictions = df_cur.select([\"row_id\", \"responder_6\"])\n",
    "    else:\n",
    "        predictions = test.select(\n",
    "            'row_id',\n",
    "            pl.lit(0.0).alias('responder_6'),\n",
    "        )\n",
    "\n",
    "    if DEBUG:\n",
    "        if time_id % 100 == 0:\n",
    "            n_nans = sum(sum(predictions.fill_nan(None).null_count().to_numpy()))\n",
    "            print(\n",
    "                f\"{date_id} {time_id:3.0f} (is_scored {is_scored}): \"\n",
    "                f\"time elps {time.time()-start_time:.4f}, # nans {n_nans}\"\n",
    "            )\n",
    "    else:\n",
    "        if (time_id==0)&(date_id==0):\n",
    "            print(predictions)\n",
    "            print((time_id, time.time()-start_time))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "    \n",
    "inference_server = jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    if not DEBUG:\n",
    "        inference_server.run_local_gateway(\n",
    "            [f'{PATH_DATA}/test.parquet', f'{PATH_DATA}/lags.parquet']\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        inference_server.run_local_gateway(\n",
    "            [\n",
    "                '/kaggle/input/js24-rmf-submission-api-debug-with-synthetic-test/synthetic_test.parquet',\n",
    "                '/kaggle/input/js24-rmf-submission-api-debug-with-synthetic-test/synthetic_lag.parquet',\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    time_est_cur = time_est/(CNT_DATES-CNT_DATES_NOT_SCORED)*200/60/60\n",
    "    time_est_scored = time_est/(CNT_DATES-CNT_DATES_NOT_SCORED)*120/60/60\n",
    "    time_est_not_scored = time_est_not_scored/(CNT_DATES_NOT_SCORED-1)*240/60/60\n",
    "    time_est_final = time_est_scored + time_est_not_scored\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Estimated current time: {time_est_cur:.4f}\")\n",
    "    print(f\"Estimated final time (is_score=True): {time_est_scored:.4f}\")\n",
    "    print(f\"Estimated final time (is_score=False): {time_est_not_scored:.4f}\")\n",
    "    print(f\"Estimated final time: {time_est_final:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11305158,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 6468154,
     "sourceId": 10460392,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6468162,
     "sourceId": 10460393,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 215844687,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.408148,
   "end_time": "2025-05-28T11:20:25.525300",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-28T11:19:56.117152",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5e5d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T07:02:35.279223Z",
     "iopub.status.busy": "2025-12-17T07:02:35.278966Z",
     "iopub.status.idle": "2025-12-17T07:03:15.200438Z",
     "shell.execute_reply": "2025-12-17T07:03:15.199587Z"
    },
    "papermill": {
     "duration": 39.926557,
     "end_time": "2025-12-17T07:03:15.202322",
     "exception": false,
     "start_time": "2025-12-17T07:02:35.275765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall -qy tensorflow\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "import json\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fe4af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T07:03:15.207144Z",
     "iopub.status.busy": "2025-12-17T07:03:15.206481Z",
     "iopub.status.idle": "2025-12-17T07:03:15.210656Z",
     "shell.execute_reply": "2025-12-17T07:03:15.210003Z"
    },
    "papermill": {
     "duration": 0.007918,
     "end_time": "2025-12-17T07:03:15.212068",
     "exception": false,
     "start_time": "2025-12-17T07:03:15.204150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    test_images_path = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/test_images\"\n",
    "    sample_sub_path = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/sample_submission.csv\"\n",
    "\n",
    "    dino_path = \"/kaggle/input/dinov2/pytorch/base/1\"\n",
    "    dino_weights_path = \"/kaggle/input/m/ravaghi/dinov2/pytorch/base/1/model.pt\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    img_size = 512\n",
    "    \n",
    "    use_tta = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef96f5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T07:03:15.215885Z",
     "iopub.status.busy": "2025-12-17T07:03:15.215682Z",
     "iopub.status.idle": "2025-12-17T07:03:38.673902Z",
     "shell.execute_reply": "2025-12-17T07:03:38.673132Z"
    },
    "papermill": {
     "duration": 23.462028,
     "end_time": "2025-12-17T07:03:38.675560",
     "exception": false,
     "start_time": "2025-12-17T07:03:15.213532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DinoSegmenter(\n",
       "  (encoder): Dinov2Model(\n",
       "    (embeddings): Dinov2Embeddings(\n",
       "      (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Dinov2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x Dinov2Layer(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attention): Dinov2Attention(\n",
       "            (attention): Dinov2SelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Dinov2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (layer_scale1): Dinov2LayerScale()\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Dinov2MLP(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_scale2): Dinov2LayerScale()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (seg_head): DinoTinyDecoder(\n",
       "    (net): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DinoTinyDecoder(nn.Module):\n",
    "    def __init__(self, in_ch=768, out_ch=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 256, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(256, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, out_ch, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, f, size):\n",
    "        return self.net(F.interpolate(f, size=size, mode=\"bilinear\", align_corners=False))\n",
    "\n",
    "\n",
    "class DinoSegmenter(nn.Module):\n",
    "    def __init__(self, encoder, processor):\n",
    "        super().__init__()\n",
    "        self.encoder, self.processor = encoder, processor\n",
    "        \n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        self.seg_head = DinoTinyDecoder(768, 1)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        imgs = (x*255).clamp(0, 255).byte().permute(0, 2, 3, 1).cpu().numpy()\n",
    "        inputs = self.processor(images=list(imgs), return_tensors=\"pt\").to(x.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            feats = self.encoder(**inputs).last_hidden_state\n",
    "        \n",
    "        B, N, C = feats.shape\n",
    "        fmap = feats[:, 1:, :].permute(0, 2, 1)\n",
    "        s = int(math.sqrt(N-1))\n",
    "        fmap = fmap.reshape(B, C, s, s)\n",
    "        \n",
    "        return fmap\n",
    "\n",
    "    def forward_seg(self, x):\n",
    "        fmap = self.forward_features(x)\n",
    "        return self.seg_head(fmap, (CFG.img_size, CFG.img_size))\n",
    "\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(CFG.dino_path, local_files_only=True)\n",
    "encoder = AutoModel.from_pretrained(CFG.dino_path, local_files_only=True).eval().to(CFG.device)\n",
    "\n",
    "model = DinoSegmenter(encoder, processor).to(CFG.device)\n",
    "model.load_state_dict(torch.load(CFG.dino_weights_path))\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2822e1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T07:03:38.680052Z",
     "iopub.status.busy": "2025-12-17T07:03:38.679823Z",
     "iopub.status.idle": "2025-12-17T07:03:38.684476Z",
     "shell.execute_reply": "2025-12-17T07:03:38.683836Z"
    },
    "papermill": {
     "duration": 0.008435,
     "end_time": "2025-12-17T07:03:38.685811",
     "exception": false,
     "start_time": "2025-12-17T07:03:38.677376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_encode(mask):\n",
    "    pixels = mask.T.flatten()\n",
    "    dots = np.where(pixels == 1)[0]\n",
    "    \n",
    "    if len(dots) == 0:\n",
    "        return \"authentic\"\n",
    "    \n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    \n",
    "    return json.dumps([int(x) for x in run_lengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562b1db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T07:03:38.690047Z",
     "iopub.status.busy": "2025-12-17T07:03:38.689632Z",
     "iopub.status.idle": "2025-12-17T07:03:40.207972Z",
     "shell.execute_reply": "2025-12-17T07:03:40.207252Z"
    },
    "papermill": {
     "duration": 1.522306,
     "end_time": "2025-12-17T07:03:40.209576",
     "exception": false,
     "start_time": "2025-12-17T07:03:38.687270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7f3f99e09a4849be1ea82a6041780a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def predict_with_tta(model, image):\n",
    "    predictions = []\n",
    "\n",
    "    pred = torch.sigmoid(model.forward_seg(image))\n",
    "    predictions.append(pred)\n",
    "\n",
    "    pred = torch.sigmoid(model.forward_seg(torch.flip(image, dims=[3])))\n",
    "    predictions.append(torch.flip(pred, dims=[3]))\n",
    "\n",
    "    pred = torch.sigmoid(model.forward_seg(torch.flip(image, dims=[2])))\n",
    "    predictions.append(torch.flip(pred, dims=[2]))\n",
    "\n",
    "    return torch.stack(predictions).mean(0)[0, 0].cpu().numpy()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, image):\n",
    "    return torch.sigmoid(model.forward_seg(image))[0,0].cpu().numpy()\n",
    "\n",
    "\n",
    "def postprocess(preds, original_size, alpha_grad=0.35):\n",
    "    gx = cv2.Sobel(preds, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(preds, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    grad_mag = np.sqrt(gx**2 + gy**2)\n",
    "    grad_norm = grad_mag / (grad_mag.max() + 1e-6)\n",
    "    enhanced = (1 - alpha_grad) * preds + alpha_grad * grad_norm\n",
    "    enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "    thr = np.mean(enhanced) + 0.3 * np.std(enhanced)\n",
    "    mask = (enhanced > thr).astype(np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    \n",
    "    mask = cv2.resize(mask, original_size, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def infer_image(image):\n",
    "    image_array = np.array(image.resize((CFG.img_size, CFG.img_size)), np.float32) / 255\n",
    "    image_array = torch.from_numpy(image_array).permute(2, 0, 1)[None].to(CFG.device)\n",
    "    \n",
    "    if CFG.use_tta:\n",
    "        preds = predict_with_tta(model, image_array)\n",
    "    else:\n",
    "        preds = predict(model, image_array)\n",
    "    \n",
    "    mask = postprocess(preds, image.size)\n",
    "    \n",
    "    area = int(mask.sum())\n",
    "    if area > 0:\n",
    "        mean_inside = float(preds[cv2.resize(mask, (CFG.img_size, CFG.img_size), interpolation=cv2.INTER_NEAREST) == 1].mean())\n",
    "    else:\n",
    "        mean_inside = 0.0\n",
    "\n",
    "    if area < 400 or mean_inside < 0.3:\n",
    "        return \"authentic\", None    \n",
    "    \n",
    "    return \"forged\", mask\n",
    "predictions = []\n",
    "\n",
    "for image_path in tqdm(sorted(os.listdir(CFG.test_images_path)), desc=\"Running Inference\"):\n",
    "    image = Image.open(Path(CFG.test_images_path)/image_path).convert(\"RGB\")\n",
    "    label, mask = infer_image(image)\n",
    "\n",
    "    if mask is None:\n",
    "        mask = np.zeros(image.size[::-1], np.uint8)\n",
    "    else:\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "\n",
    "    if label == \"authentic\":\n",
    "        annotation = \"authentic\"\n",
    "    else:\n",
    "        annotation = rle_encode((mask > 0).astype(np.uint8))\n",
    "\n",
    "    predictions.append({\n",
    "        \"case_id\": Path(image_path).stem,\n",
    "        \"annotation\": annotation\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "060678d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T07:03:40.214375Z",
     "iopub.status.busy": "2025-12-17T07:03:40.213902Z",
     "iopub.status.idle": "2025-12-17T07:03:40.264203Z",
     "shell.execute_reply": "2025-12-17T07:03:40.263586Z"
    },
    "papermill": {
     "duration": 0.054244,
     "end_time": "2025-12-17T07:03:40.265688",
     "exception": false,
     "start_time": "2025-12-17T07:03:40.211444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>authentic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id annotation\n",
       "0      45  authentic"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "predictions[\"case_id\"] = predictions[\"case_id\"].astype(str)\n",
    "\n",
    "submission = pd.read_csv(CFG.sample_sub_path)\n",
    "submission[\"case_id\"] = submission[\"case_id\"].astype(str)\n",
    "\n",
    "submission = submission[[\"case_id\"]].merge(predictions, on=\"case_id\", how=\"left\")\n",
    "submission[\"annotation\"] = submission[\"annotation\"].fillna(\"authentic\")\n",
    "submission[[\"case_id\", \"annotation\"]].to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14878066,
     "sourceId": 113558,
     "sourceType": "competition"
    },
    {
     "modelId": 986,
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 504592,
     "modelInstanceId": 489174,
     "sourceId": 648498,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 70.093931,
   "end_time": "2025-12-17T07:03:42.826076",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-17T07:02:32.732145",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "022545293ed0483f923dec1890d37dde": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "038fb097d6f24f03978d8a5bdc0f40e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6e15cd3074a44c9ea63808ef94089724",
       "placeholder": "​",
       "style": "IPY_MODEL_599f58fdbc3843f68328f7001dbdf7c1",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:01&lt;00:00,  1.49s/it]"
      }
     },
     "4e7f3f99e09a4849be1ea82a6041780a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c41c1c2300614824a3353b11776fabe9",
        "IPY_MODEL_6aa3c6d2b07744d4a6972e9692f94792",
        "IPY_MODEL_038fb097d6f24f03978d8a5bdc0f40e2"
       ],
       "layout": "IPY_MODEL_022545293ed0483f923dec1890d37dde",
       "tabbable": null,
       "tooltip": null
      }
     },
     "599f58fdbc3843f68328f7001dbdf7c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5d6bae2b273040ef8875957ab3a4f65f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6aa3c6d2b07744d4a6972e9692f94792": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d6bae2b273040ef8875957ab3a4f65f",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f14616706f2c4ea7bf117ea446ea76da",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "6e15cd3074a44c9ea63808ef94089724": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a82cc97c6edf4bfb92b2cf30eaf29726": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c41c1c2300614824a3353b11776fabe9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a82cc97c6edf4bfb92b2cf30eaf29726",
       "placeholder": "​",
       "style": "IPY_MODEL_ef79357b6baa4093b4267ff229bbbc13",
       "tabbable": null,
       "tooltip": null,
       "value": "Running Inference: 100%"
      }
     },
     "ef79357b6baa4093b4267ff229bbbc13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f14616706f2c4ea7bf117ea446ea76da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

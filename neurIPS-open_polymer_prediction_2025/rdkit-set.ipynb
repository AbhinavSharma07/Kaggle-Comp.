{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rdkit\n!pip install /kaggle/input/rdkit-install-whl/rdkit_wheel/rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:13:03.311578Z","iopub.execute_input":"2025-06-18T10:13:03.312072Z","iopub.status.idle":"2025-06-18T10:13:07.573303Z","shell.execute_reply.started":"2025-06-18T10:13:03.312040Z","shell.execute_reply":"2025-06-18T10:13:07.568102Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rdkit in /usr/local/lib/python3.10/site-packages (2025.3.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit) (11.2.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (2.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[31mERROR: rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install lightgbm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:13:07.574515Z","iopub.execute_input":"2025-06-18T10:13:07.574789Z","iopub.status.idle":"2025-06-18T10:13:11.617523Z","shell.execute_reply.started":"2025-06-18T10:13:07.574759Z","shell.execute_reply":"2025-06-18T10:13:11.611296Z"}},"outputs":[{"name":"stdout","text":"Collecting lightgbm\n  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/site-packages (from lightgbm) (2.0.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from lightgbm) (1.15.2)\nInstalling collected packages: lightgbm\nSuccessfully installed lightgbm-4.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors, rdMolDescriptors\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:13:11.619740Z","iopub.execute_input":"2025-06-18T10:13:11.619998Z","iopub.status.idle":"2025-06-18T10:13:12.018055Z","shell.execute_reply.started":"2025-06-18T10:13:11.619969Z","shell.execute_reply":"2025-06-18T10:13:12.013056Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"molecules = [\n    ('CCO', 'Ethanol - simple alcohol'),\n    ('CCCCCCCC', 'Octane - long chain'),\n    ('c1ccccc1', 'Benzene - aromatic ring'),\n]\n\nfor smiles, description in molecules:\n    mol = Chem.MolFromSmiles(smiles)\n    \n    print(f\"\\n{description}\")\n    print(f\"SMILES: {smiles}\")\n    print(f\"  Molecular Weight: {Descriptors.MolWt(mol):.1f}\")\n    print(f\"  LogP (oiliness): {Descriptors.MolLogP(mol):.2f}\")\n    print(f\"  Rotatable Bonds: {Descriptors.NumRotatableBonds(mol)}\")\n    print(f\"  Aromatic Rings: {Descriptors.NumAromaticRings(mol)}\")\n    print(f\"  Complexity (BertzCT): {Descriptors.BertzCT(mol):.0f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:13:22.073414Z","iopub.execute_input":"2025-06-18T10:13:22.073891Z","iopub.status.idle":"2025-06-18T10:13:22.089708Z","shell.execute_reply.started":"2025-06-18T10:13:22.073864Z","shell.execute_reply":"2025-06-18T10:13:22.084047Z"}},"outputs":[{"name":"stdout","text":"\nEthanol - simple alcohol\nSMILES: CCO\n  Molecular Weight: 46.1\n  LogP (oiliness): -0.00\n  Rotatable Bonds: 0\n  Aromatic Rings: 0\n  Complexity (BertzCT): 3\n\nOctane - long chain\nSMILES: CCCCCCCC\n  Molecular Weight: 114.2\n  LogP (oiliness): 3.37\n  Rotatable Bonds: 5\n  Aromatic Rings: 0\n  Complexity (BertzCT): 25\n\nBenzene - aromatic ring\nSMILES: c1ccccc1\n  Molecular Weight: 78.1\n  LogP (oiliness): 1.69\n  Rotatable Bonds: 0\n  Aromatic Rings: 1\n  Complexity (BertzCT): 72\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Load data\ntrain_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\ntest_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:13:44.061370Z","iopub.execute_input":"2025-06-18T10:13:44.061725Z","iopub.status.idle":"2025-06-18T10:13:44.107446Z","shell.execute_reply.started":"2025-06-18T10:13:44.061696Z","shell.execute_reply":"2025-06-18T10:13:44.103023Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from rdkit.Chem import Descriptors\nfrom rdkit import Chem\nimport numpy as np\n\ndef get_molecular_descriptors(max_autocorr=10):\n    \"\"\"Get molecular descriptors - either hardcoded list or auto-discovered\"\"\"\n\n    descriptor_list_all = []\n    test_mol = Chem.MolFromSmiles('CCO')\n\n    # Collect all valid descriptors first\n    for name in dir(Descriptors):\n        if not name.startswith('_'):\n            try:\n                func = getattr(Descriptors, name)\n                if callable(func):\n                    result = func(test_mol)\n                    if isinstance(result, (int, float)) and not np.isnan(result):\n                        descriptor_list_all.append((name, func))\n            except:\n                pass\n\n    print(f\"üîç Total discovered descriptors before filtering: {len(descriptor_list_all)}\")\n\n    # Sort AUTOCORR2D descriptors by their numeric suffix\n    autocorr_descriptors = [\n        (name, func)\n        for name, func in descriptor_list_all\n        if name.startswith('AUTOCORR2D_')\n    ]\n    autocorr_descriptors.sort(key=lambda x: int(x[0].split('_')[-1]))\n\n    # Select only the lowest-numbered ones\n    limited_autocorr = autocorr_descriptors[:max_autocorr]\n\n    # Include all other descriptors\n    other_descriptors = [\n        (name, func)\n        for name, func in descriptor_list_all\n        if not name.startswith('AUTOCORR2D_')\n    ]\n\n    # Final descriptor list\n    descriptor_list = limited_autocorr + other_descriptors\n\n    print(f\"‚úÖ Auto-discovered {len(descriptor_list)} descriptors (limited to {max_autocorr} AUTOCORR2D):\")\n    names = [name for name, _ in descriptor_list]\n    print(\"  \" + \", \".join(names))\n\n    feature_names = [name for name, _ in descriptor_list]\n    return descriptor_list, feature_names\n\nmolecular_descriptors =  get_molecular_descriptors(max_autocorr=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:14:02.873800Z","iopub.execute_input":"2025-06-18T10:14:02.874117Z","iopub.status.idle":"2025-06-18T10:14:02.900584Z","shell.execute_reply.started":"2025-06-18T10:14:02.874090Z","shell.execute_reply":"2025-06-18T10:14:02.895370Z"}},"outputs":[{"name":"stdout","text":"üîç Total discovered descriptors before filtering: 409\n‚úÖ Auto-discovered 227 descriptors (limited to 10 AUTOCORR2D):\n  AUTOCORR2D_1, AUTOCORR2D_2, AUTOCORR2D_3, AUTOCORR2D_4, AUTOCORR2D_5, AUTOCORR2D_6, AUTOCORR2D_7, AUTOCORR2D_8, AUTOCORR2D_9, AUTOCORR2D_10, AvgIpc, BCUT2D_CHGHI, BCUT2D_CHGLO, BCUT2D_LOGPHI, BCUT2D_LOGPLOW, BCUT2D_MRHI, BCUT2D_MRLOW, BCUT2D_MWHI, BCUT2D_MWLOW, BalabanJ, BertzCT, Chi0, Chi0n, Chi0v, Chi1, Chi1n, Chi1v, Chi2n, Chi2v, Chi3n, Chi3v, Chi4n, Chi4v, EState_VSA1, EState_VSA10, EState_VSA11, EState_VSA2, EState_VSA3, EState_VSA4, EState_VSA5, EState_VSA6, EState_VSA7, EState_VSA8, EState_VSA9, ExactMolWt, FpDensityMorgan1, FpDensityMorgan2, FpDensityMorgan3, FractionCSP3, HallKierAlpha, HeavyAtomCount, HeavyAtomMolWt, Ipc, Kappa1, Kappa2, Kappa3, LabuteASA, MaxAbsEStateIndex, MaxAbsPartialCharge, MaxEStateIndex, MaxPartialCharge, MinAbsEStateIndex, MinAbsPartialCharge, MinEStateIndex, MinPartialCharge, MolLogP, MolMR, MolWt, NHOHCount, NOCount, NumAliphaticCarbocycles, NumAliphaticHeterocycles, NumAliphaticRings, NumAmideBonds, NumAromaticCarbocycles, NumAromaticHeterocycles, NumAromaticRings, NumAtomStereoCenters, NumBridgeheadAtoms, NumHAcceptors, NumHDonors, NumHeteroatoms, NumHeterocycles, NumRadicalElectrons, NumRotatableBonds, NumSaturatedCarbocycles, NumSaturatedHeterocycles, NumSaturatedRings, NumSpiroAtoms, NumUnspecifiedAtomStereoCenters, NumValenceElectrons, PEOE_VSA1, PEOE_VSA10, PEOE_VSA11, PEOE_VSA12, PEOE_VSA13, PEOE_VSA14, PEOE_VSA2, PEOE_VSA3, PEOE_VSA4, PEOE_VSA5, PEOE_VSA6, PEOE_VSA7, PEOE_VSA8, PEOE_VSA9, Phi, RingCount, SMR_VSA1, SMR_VSA10, SMR_VSA2, SMR_VSA3, SMR_VSA4, SMR_VSA5, SMR_VSA6, SMR_VSA7, SMR_VSA8, SMR_VSA9, SPS, SlogP_VSA1, SlogP_VSA10, SlogP_VSA11, SlogP_VSA12, SlogP_VSA2, SlogP_VSA3, SlogP_VSA4, SlogP_VSA5, SlogP_VSA6, SlogP_VSA7, SlogP_VSA8, SlogP_VSA9, TPSA, VSA_EState1, VSA_EState10, VSA_EState2, VSA_EState3, VSA_EState4, VSA_EState5, VSA_EState6, VSA_EState7, VSA_EState8, VSA_EState9, fr_Al_COO, fr_Al_OH, fr_Al_OH_noTert, fr_ArN, fr_Ar_COO, fr_Ar_N, fr_Ar_NH, fr_Ar_OH, fr_COO, fr_COO2, fr_C_O, fr_C_O_noCOO, fr_C_S, fr_HOCCN, fr_Imine, fr_NH0, fr_NH1, fr_NH2, fr_N_O, fr_Ndealkylation1, fr_Ndealkylation2, fr_Nhpyrrole, fr_SH, fr_aldehyde, fr_alkyl_carbamate, fr_alkyl_halide, fr_allylic_oxid, fr_amide, fr_amidine, fr_aniline, fr_aryl_methyl, fr_azide, fr_azo, fr_barbitur, fr_benzene, fr_benzodiazepine, fr_bicyclic, fr_diazo, fr_dihydropyridine, fr_epoxide, fr_ester, fr_ether, fr_furan, fr_guanido, fr_halogen, fr_hdrzine, fr_hdrzone, fr_imidazole, fr_imide, fr_isocyan, fr_isothiocyan, fr_ketone, fr_ketone_Topliss, fr_lactam, fr_lactone, fr_methoxy, fr_morpholine, fr_nitrile, fr_nitro, fr_nitro_arom, fr_nitro_arom_nonortho, fr_nitroso, fr_oxazole, fr_oxime, fr_para_hydroxylation, fr_phenol, fr_phenol_noOrthoHbond, fr_phos_acid, fr_phos_ester, fr_piperdine, fr_piperzine, fr_priamide, fr_prisulfonamd, fr_pyridine, fr_quatN, fr_sulfide, fr_sulfonamd, fr_sulfone, fr_term_acetylene, fr_tetrazole, fr_thiazole, fr_thiocyan, fr_thiophene, fr_unbrch_alkane, fr_urea, qed\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def smiles_to_features(smiles_list, descriptor_functions):\n   \"\"\"Convert SMILES strings to raw feature matrix\"\"\"\n   \n   features = []\n   total = len(smiles_list)\n   \n   print(f\"Processing {total} SMILES...\", end=\"\", flush=True)\n   \n   for i, smiles in enumerate(smiles_list):\n       # Progress indicator every 1000 molecules or at milestones\n       if i > 0 and (i % 1000 == 0 or i == total - 1):\n           print(f\" {i+1}/{total}\", end=\"\", flush=True)\n       \n       mol_features = []\n       try:\n           mol = Chem.MolFromSmiles(smiles)\n           if mol is None:\n               # Invalid SMILES - fill with NaN\n               mol_features = [np.nan] * len(descriptor_functions)\n           else:\n               # Calculate each descriptor\n               for name, func in descriptor_functions:\n                   try:\n                       value = func(mol)\n                       # Handle problematic values\n                       if np.isinf(value) or abs(value) > 1e10:\n                           value = np.nan\n                       mol_features.append(value)\n                   except:\n                       # Descriptor calculation failed\n                       mol_features.append(np.nan)\n       except:\n           # Complete failure - fill entire row with NaN\n           mol_features = [np.nan] * len(descriptor_functions)\n       \n       features.append(mol_features)\n   \n   print(\" ‚úÖ\", flush=True)\n   return np.array(features, dtype=float)\n\ndescriptor_functions, feature_names = molecular_descriptors\nX_raw = smiles_to_features(train_df['SMILES'].values, descriptor_functions)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:14:37.694333Z","iopub.execute_input":"2025-06-18T10:14:37.694753Z","iopub.status.idle":"2025-06-18T10:17:06.259491Z","shell.execute_reply.started":"2025-06-18T10:14:37.694724Z","shell.execute_reply":"2025-06-18T10:17:06.254872Z"}},"outputs":[{"name":"stdout","text":"Processing 7973 SMILES... 1001/7973 2001/7973 3001/7973 4001/7973 5001/7973 6001/7973 7001/7973 7973/7973 ‚úÖ\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def clean_features(X):\n   \"\"\"Handle NaN/inf values and impute missing data\"\"\"\n   X[np.isinf(X)] = np.nan\n   \n   # Count and report missing values\n   missing = np.isnan(X).sum()\n   print(f\"üßπ Cleaned {missing:,} missing values ({missing/X.size*100:.1f}%)\")\n   \n   # Median imputation\n   for i in range(X.shape[1]):\n       col = X[:, i]\n       if np.isnan(col).any():\n           X[np.isnan(col), i] = np.nanmedian(col) if not np.isnan(np.nanmedian(col)) else 0\n   \n   return X\n\nX = clean_features(X_raw)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:17:12.060978Z","iopub.execute_input":"2025-06-18T10:17:12.061303Z","iopub.status.idle":"2025-06-18T10:17:12.087956Z","shell.execute_reply.started":"2025-06-18T10:17:12.061277Z","shell.execute_reply":"2025-06-18T10:17:12.081826Z"}},"outputs":[{"name":"stdout","text":"üßπ Cleaned 96,915 missing values (5.4%)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def train_target_property(X, train_df, target_name):\n    \n    # Get targets (only non-null values)\n    mask = train_df[target_name].notna()\n    \n    X_target = X[mask]\n    y_target = train_df[target_name].values[mask]\n\n    print(f\"üìä Training on {len(y_target)} samples with {target_name} values\")\n    print(f\"üìà Target range: {y_target.min():.4f} to {y_target.max():.4f}\")\n    \n    # Scale features\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X_target)\n    \n    # LightGBM parameters\n    params = {\n        'objective': 'regression',\n        'metric': 'mae',\n        'boosting_type': 'gbdt',\n        'num_leaves': 127,           \n        'learning_rate': 0.07,       \n        'feature_fraction': 0.8,     \n        'bagging_fraction': 0.9,     \n        'bagging_freq': 1,           # Bag every iteration\n        'lambda_l1': 0.1,            # L1 regularization\n        'lambda_l2': 0.1,            # L2 regularization\n        'min_data_in_leaf': 10,      # Prevent overfitting\n        'verbose': -1,\n        'random_state': 42\n    }\n    \n    # 5-fold cross-validation\n    cv_scores = []\n    models = []\n    \n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n        y_train, y_val = y_target[train_idx], y_target[val_idx]\n        \n        train_data = lgb.Dataset(X_train, label=y_train)\n        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n        \n        model = lgb.train(\n            params,\n            train_data,\n            valid_sets=[val_data],\n            num_boost_round=2000,\n            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n        )\n        \n        val_pred = model.predict(X_val)\n        cv_score = mean_absolute_error(y_val, val_pred)\n        cv_scores.append(cv_score)\n        models.append(model)\n        \n        print(f\"----Fold {fold+1} Complete / MAE = {cv_score:.4f}\", flush=True)\n    \n    cv_mean = np.mean(cv_scores)\n    print(f\"===CV: {cv_mean:.4f} ¬± {np.std(cv_scores):.3f}===\")\n    return models, scaler, feature_names, cv_mean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:17:16.435253Z","iopub.execute_input":"2025-06-18T10:17:16.435672Z","iopub.status.idle":"2025-06-18T10:17:16.450703Z","shell.execute_reply.started":"2025-06-18T10:17:16.435636Z","shell.execute_reply":"2025-06-18T10:17:16.446399Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Define all target properties\ntargets = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n\n# Store trained models and scalers\ntrained_models = {}\ntrained_scalers = {}\ncv_scores = []\n\n# Train each target - collect results for summary\nfor target in targets:\n    print(f\"Training {target}...\")\n    models, scaler, features, cv_score = train_target_property(X, train_df, target)\n    trained_models[target] = models\n    trained_scalers[target] = scaler\n    cv_scores.append(cv_score)\n    print()\n\n# Clean summary with average\nprint(\"=\" * 40)\nprint(f\"Trained: {len(targets)} targets √ó 5 CV folds = {len(targets) * 5} models\")\nprint(f\"Average CV MAE across all targets: {np.mean(cv_scores):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:17:26.687364Z","iopub.execute_input":"2025-06-18T10:17:26.687771Z","iopub.status.idle":"2025-06-18T10:19:57.090851Z","shell.execute_reply.started":"2025-06-18T10:17:26.687738Z","shell.execute_reply":"2025-06-18T10:19:57.086082Z"}},"outputs":[{"name":"stdout","text":"Training Tg...\nüìä Training on 511 samples with Tg values\nüìà Target range: -148.0297 to 472.2500\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[45]\tvalid_0's l1: 53.4334\n----Fold 1 Complete / MAE = 53.4334\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[120]\tvalid_0's l1: 57.8898\n----Fold 2 Complete / MAE = 57.8898\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[48]\tvalid_0's l1: 49.6651\n----Fold 3 Complete / MAE = 49.6651\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[35]\tvalid_0's l1: 43.8116\n----Fold 4 Complete / MAE = 43.8116\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[41]\tvalid_0's l1: 45.8876\n----Fold 5 Complete / MAE = 45.8876\n===CV: 50.1375 ¬± 5.085===\n\nTraining FFV...\nüìä Training on 7030 samples with FFV values\nüìà Target range: 0.2270 to 0.7771\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1362]\tvalid_0's l1: 0.00688365\n----Fold 1 Complete / MAE = 0.0069\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1637]\tvalid_0's l1: 0.00665245\n----Fold 2 Complete / MAE = 0.0067\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[823]\tvalid_0's l1: 0.00647531\n----Fold 3 Complete / MAE = 0.0065\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1694]\tvalid_0's l1: 0.00628582\n----Fold 4 Complete / MAE = 0.0063\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1151]\tvalid_0's l1: 0.00708481\n----Fold 5 Complete / MAE = 0.0071\n===CV: 0.0067 ¬± 0.000===\n\nTraining Tc...\nüìä Training on 737 samples with Tc values\nüìà Target range: 0.0465 to 0.5240\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[150]\tvalid_0's l1: 0.0276313\n----Fold 1 Complete / MAE = 0.0276\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[66]\tvalid_0's l1: 0.0276907\n----Fold 2 Complete / MAE = 0.0277\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[73]\tvalid_0's l1: 0.0293718\n----Fold 3 Complete / MAE = 0.0294\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[49]\tvalid_0's l1: 0.0242708\n----Fold 4 Complete / MAE = 0.0243\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[61]\tvalid_0's l1: 0.0286937\n----Fold 5 Complete / MAE = 0.0287\n===CV: 0.0275 ¬± 0.002===\n\nTraining Density...\nüìä Training on 613 samples with Density values\nüìà Target range: 0.7487 to 1.8410\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[350]\tvalid_0's l1: 0.0337179\n----Fold 1 Complete / MAE = 0.0337\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[172]\tvalid_0's l1: 0.0513638\n----Fold 2 Complete / MAE = 0.0514\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[212]\tvalid_0's l1: 0.0277831\n----Fold 3 Complete / MAE = 0.0278\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[119]\tvalid_0's l1: 0.021768\n----Fold 4 Complete / MAE = 0.0218\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[194]\tvalid_0's l1: 0.0311376\n----Fold 5 Complete / MAE = 0.0311\n===CV: 0.0332 ¬± 0.010===\n\nTraining Rg...\nüìä Training on 614 samples with Rg values\nüìà Target range: 9.7284 to 34.6729\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[63]\tvalid_0's l1: 2.05089\n----Fold 1 Complete / MAE = 2.0509\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[41]\tvalid_0's l1: 1.87817\n----Fold 2 Complete / MAE = 1.8782\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[41]\tvalid_0's l1: 2.04418\n----Fold 3 Complete / MAE = 2.0442\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[52]\tvalid_0's l1: 1.43651\n----Fold 4 Complete / MAE = 1.4365\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[176]\tvalid_0's l1: 1.6832\n----Fold 5 Complete / MAE = 1.6832\n===CV: 1.8186 ¬± 0.234===\n\n========================================\nTrained: 5 targets √ó 5 CV folds = 25 models\nAverage CV MAE across all targets: 10.4047\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def predict_target_property(test_df, target_name, models, scaler):\n    \n    print(f\"PREDICTING: {target_name}\")\n    \n    if models is None or scaler is None:\n        print(f\"‚ùå No trained model available for {target_name}, returning zeros\")\n        return np.zeros(len(test_df))\n    \n    # Get molecular features - step by step\n    descriptor_functions, _ = molecular_descriptors\n    X_raw = smiles_to_features(test_df['SMILES'].values, descriptor_functions)\n    X = clean_features(X_raw)\n    \n    # Scale features using same scaler from training\n    X_scaled = scaler.transform(X)\n    \n    # Average predictions from all CV folds\n    fold_predictions = []\n    for model in models:\n        pred = model.predict(X_scaled)\n        fold_predictions.append(pred)\n    \n    predictions = np.mean(fold_predictions, axis=0)\n    print(f\"üìä Predictions range: {predictions.min():.4f} to {predictions.max():.4f}\")\n    \n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:20:38.608554Z","iopub.execute_input":"2025-06-18T10:20:38.608904Z","iopub.status.idle":"2025-06-18T10:20:38.621457Z","shell.execute_reply.started":"2025-06-18T10:20:38.608875Z","shell.execute_reply":"2025-06-18T10:20:38.616788Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(f\"\\nMAKING PREDICTIONS...\")\nall_predictions = {}\nfor target in targets:\n    predictions = predict_target_property(\n        test_df, target, trained_models[target], trained_scalers[target]\n    )\n    all_predictions[target] = predictions\n\n# Create submission\nsubmission = pd.DataFrame({'id': test_df['id']})\nfor target in targets:\n    submission[target] = all_predictions[target]\n\nsubmission.to_csv('submission.csv', index=False)\n\nprint(f\"Predicted: {len(test_df)} test samples\")\nprint(f\"Saved: submission.csv\")\n\nprint(f\"\\nüëÄ SUBMISSION PREVIEW:\")\nprint(submission.head().to_string(index=False, float_format='%.4f'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T10:20:41.922352Z","iopub.execute_input":"2025-06-18T10:20:41.922686Z","iopub.status.idle":"2025-06-18T10:20:42.426090Z","shell.execute_reply.started":"2025-06-18T10:20:41.922661Z","shell.execute_reply":"2025-06-18T10:20:42.422472Z"}},"outputs":[{"name":"stdout","text":"\nMAKING PREDICTIONS...\nPREDICTING: Tg\nProcessing 3 SMILES... 3/3 ‚úÖ\nüßπ Cleaned 37 missing values (5.4%)\nüìä Predictions range: 80.4436 to 150.5664\nPREDICTING: FFV\nProcessing 3 SMILES... 3/3 ‚úÖ\nüßπ Cleaned 37 missing values (5.4%)\nüìä Predictions range: 0.3498 to 0.3776\nPREDICTING: Tc\nProcessing 3 SMILES... 3/3 ‚úÖ\nüßπ Cleaned 37 missing values (5.4%)\nüìä Predictions range: 0.1822 to 0.2656\nPREDICTING: Density\nProcessing 3 SMILES... 3/3 ‚úÖ\nüßπ Cleaned 37 missing values (5.4%)\nüìä Predictions range: 1.0847 to 1.1396\nPREDICTING: Rg\nProcessing 3 SMILES... 3/3 ‚úÖ\nüßπ Cleaned 37 missing values (5.4%)\nüìä Predictions range: 18.8712 to 19.8186\nPredicted: 3 test samples\nSaved: submission.csv\n\nüëÄ SUBMISSION PREVIEW:\n        id       Tg    FFV     Tc  Density      Rg\n1109053969 138.9369 0.3728 0.1822   1.1396 18.8712\n1422188626 150.5664 0.3776 0.2438   1.0847 19.8186\n2032016830  80.4436 0.3498 0.2656   1.0986 19.6219\n","output_type":"stream"}],"execution_count":17}]}